{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1889f6d3",
      "metadata": {
        "id": "1889f6d3"
      },
      "source": [
        "\n",
        "# Transfer Learning with ResNet & VGG Encoders (Keras)\n",
        "\n",
        "Objectives:\n",
        "\n",
        "- **Problem 1 (Code review)**: Show what changes vs. previous U-Net, and how transfer learning is used.\n",
        "- **Problem 2 (Rewrite)**: Provide both **ResNet** and **VGG** encoder variants of U-Net.\n",
        "- **Problem 3 (Train & compare)**: Train/validate both and report metrics + qualitative results.\n",
        "\n",
        "**Versions targeted:** TensorFlow 1.14.x + Keras 2.3.x (works with TF 2.x via `tf.keras` fallback too)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ecb03baa",
      "metadata": {
        "id": "ecb03baa"
      },
      "outputs": [],
      "source": [
        "# Environment checks (works with Keras 2.3.x or tf.keras)\n",
        "import os, sys, random, math, gc, time, json, glob, pathlib, shutil\n",
        "import numpy as np\n",
        "import PIL.Image as Image\n",
        "import tensorflow as tf\n",
        "\n",
        "SEED = 42\n",
        "np.random.seed(SEED)\n",
        "random.seed(SEED)\n",
        "try:\n",
        "    import keras\n",
        "    from keras import backend as K\n",
        "    from keras.layers import (Input, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D,\n",
        "                              BatchNormalization, Activation, Dropout, Concatenate)\n",
        "    from keras.models import Model\n",
        "    from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
        "    from keras.optimizers import Adam\n",
        "    from keras.preprocessing.image import ImageDataGenerator\n",
        "    from keras.applications import ResNet50, VGG16\n",
        "    USING_TF_KERAS = False\n",
        "except Exception as e:\n",
        "    # Fallback to tf.keras\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras import backend as K\n",
        "    from tensorflow.keras.layers import (Input, Conv2D, Conv2DTranspose, MaxPooling2D, UpSampling2D,\n",
        "                              BatchNormalization, Activation, Dropout, Concatenate)\n",
        "    from tensorflow.keras.models import Model\n",
        "    from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau, CSVLogger\n",
        "    from tensorflow.keras.optimizers import Adam\n",
        "    from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "    from tensorflow.keras.applications import ResNet50, VGG16\n",
        "    USING_TF_KERAS = True\n",
        "\n",
        "print(\"Keras backend:\", \"tf.keras\" if USING_TF_KERAS else \"keras\", \" — TF version:\", tf.__version__)\n",
        "\n",
        "# GPU memory growth (optional)\n",
        "try:\n",
        "    gpus = tf.config.experimental.list_physical_devices('GPU')\n",
        "    for g in gpus:\n",
        "        tf.config.experimental.set_memory_growth(g, True)\n",
        "    print(\"GPUs:\", gpus)\n",
        "except Exception as _:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2c60e820",
      "metadata": {
        "id": "2c60e820"
      },
      "source": [
        "\n",
        "## Configuration\n",
        "- `DATA_DIR` should contain `train/images` and `train/masks` folders with 101×101 PNGs (TGS Salt).\n",
        "- Images are padded to 128×128 and repeated to 3 channels for ImageNet backbones.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "34268aa4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "34268aa4",
        "outputId": "6229c5a6-b3c1-4b56-b84a-b8e558a3ce9a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'os' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3674294578.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Paths & hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mDATA_DIR\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TGS_DIR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"/content/tgs\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# change if needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mIMG_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mBATCH_SIZE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'os' is not defined"
          ]
        }
      ],
      "source": [
        "# Paths & hyperparameters\n",
        "DATA_DIR = os.environ.get(\"TGS_DIR\", \"/content/tgs\")  # change if needed\n",
        "IMG_SIZE = 128\n",
        "BATCH_SIZE = 16\n",
        "EPOCHS = 15\n",
        "VAL_SPLIT = 0.2\n",
        "FREEZE_ENCODER = True  # freeze backbone at start\n",
        "\n",
        "# For quick smoke runs if dataset is missing:\n",
        "FALLBACK_SYNTHETIC = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "157673d1",
      "metadata": {
        "id": "157673d1"
      },
      "source": [
        "\n",
        "## Data loading utilities\n",
        "- Loads image/mask PNGs.\n",
        "- Pads to 128×128 (constant=0).\n",
        "- Converts grayscale to 3-channels by repeat for encoders.\n",
        "- Simple on-the-fly augmentation (flips) applied **consistently** to image/mask.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c98a95b",
      "metadata": {
        "id": "6c98a95b"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def _pad_to_square(img_np, target=128, constant=0):\n",
        "    h, w = img_np.shape[:2]\n",
        "    pad_h = target - h\n",
        "    pad_w = target - w\n",
        "    assert pad_h >= 0 and pad_w >= 0\n",
        "    if img_np.ndim == 2:\n",
        "        img_np = np.pad(img_np, ((0,pad_h),(0,pad_w)), mode='constant', constant_values=constant)\n",
        "    else:\n",
        "        img_np = np.pad(img_np, ((0,pad_h),(0,pad_w),(0,0)), mode='constant', constant_values=constant)\n",
        "    return img_np\n",
        "\n",
        "def load_tgs_pair(img_path, mask_path):\n",
        "    img = Image.open(img_path).convert(\"L\")\n",
        "    msk = Image.open(mask_path).convert(\"L\")\n",
        "    img = np.array(img, dtype=np.uint8)\n",
        "    msk = np.array(msk, dtype=np.uint8)\n",
        "    # pad to 128×128\n",
        "    img = _pad_to_square(img, IMG_SIZE, 0)\n",
        "    msk = _pad_to_square(msk, IMG_SIZE, 0)\n",
        "    # scale to [0,1]\n",
        "    img = img.astype(np.float32) / 255.0\n",
        "    msk = (msk > 127).astype(np.float32)  # binary\n",
        "    # 3-channel for encoders\n",
        "    img3 = np.repeat(img[...,None], 3, axis=-1)\n",
        "    return img3, msk[...,None]\n",
        "\n",
        "def load_tgs_dataset(data_dir):\n",
        "    img_dir = os.path.join(data_dir, \"train\", \"images\")\n",
        "    mask_dir = os.path.join(data_dir, \"train\", \"masks\")\n",
        "    img_paths = sorted(glob.glob(os.path.join(img_dir, \"*.png\")))\n",
        "    mask_paths = [os.path.join(mask_dir, os.path.basename(p)) for p in img_paths]\n",
        "    X, Y = [], []\n",
        "    for ip, mp in zip(img_paths, mask_paths):\n",
        "        if not os.path.exists(mp):\n",
        "            continue\n",
        "        x, y = load_tgs_pair(ip, mp)\n",
        "        X.append(x); Y.append(y)\n",
        "    X = np.stack(X, 0); Y = np.stack(Y, 0)\n",
        "    return X, Y\n",
        "\n",
        "def get_data_or_synthetic():\n",
        "    if os.path.exists(os.path.join(DATA_DIR, \"train\", \"images\")):\n",
        "        X, Y = load_tgs_dataset(DATA_DIR)\n",
        "        print(\"Loaded TGS:\", X.shape, Y.shape)\n",
        "    else:\n",
        "        if not FALLBACK_SYNTHETIC:\n",
        "            raise FileNotFoundError(\"TGS dataset not found. Set DATA_DIR correctly.\")\n",
        "        # Tiny synthetic set (blobs)\n",
        "        n = 64\n",
        "        X = np.zeros((n, IMG_SIZE, IMG_SIZE, 3), dtype=np.float32)\n",
        "        Y = np.zeros((n, IMG_SIZE, IMG_SIZE, 1), dtype=np.float32)\n",
        "        for i in range(n):\n",
        "            cx, cy = np.random.randint(20, IMG_SIZE-20, size=2)\n",
        "            rr = np.random.randint(8, 18)\n",
        "            yy, xx = np.ogrid[:IMG_SIZE, :IMG_SIZE]\n",
        "            mask = (xx-cx)**2 + (yy-cy)**2 <= rr**2\n",
        "            Y[i, mask, 0] = 1.0\n",
        "            X[i,...] = np.repeat((Y[i,...]*0.7 + np.random.rand(IMG_SIZE,IMG_SIZE,1)*0.3), 3, axis=-1)\n",
        "        print(\"Using synthetic data:\", X.shape, Y.shape)\n",
        "    X_tr, X_va, Y_tr, Y_va = train_test_split(X, Y, test_size=VAL_SPLIT, random_state=SEED)\n",
        "    return X_tr, Y_tr, X_va, Y_va\n",
        "\n",
        "X_tr, Y_tr, X_va, Y_va = get_data_or_synthetic()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7c9bed5",
      "metadata": {
        "id": "a7c9bed5"
      },
      "source": [
        "\n",
        "## Losses & metrics\n",
        "- **Dice coefficient** & **IoU** for monitoring.\n",
        "- Combined **BCE + Dice loss** often works well for salt segmentation.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52476b8c",
      "metadata": {
        "id": "52476b8c"
      },
      "outputs": [],
      "source": [
        "def dice_coef(y_true, y_pred, smooth=1.0):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
        "\n",
        "def iou_coef(y_true, y_pred, smooth=1.0):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    union = K.sum(y_true_f) + K.sum(y_pred_f) - intersection\n",
        "    return (intersection + smooth) / (union + smooth)\n",
        "\n",
        "def bce_dice_loss(y_true, y_pred):\n",
        "    return keras.losses.binary_crossentropy(y_true, y_pred) + (1.0 - dice_coef(y_true, y_pred))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ab98b5e",
      "metadata": {
        "id": "5ab98b5e"
      },
      "source": [
        "\n",
        "## Model builders\n",
        "We compose a U-Net-style decoder on top of either **ResNet50** or **VGG16** backbones (`include_top=False`, `weights='imagenet'`).  \n",
        "Encoder can be frozen for initial epochs, then optionally unfrozen.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0cd10b2b",
      "metadata": {
        "id": "0cd10b2b"
      },
      "outputs": [],
      "source": [
        "def conv_block(x, filters, k=3, act='relu', bn=True, dp=0.0):\n",
        "    x = Conv2D(filters, k, padding='same')(x)\n",
        "    if bn: x = BatchNormalization()(x)\n",
        "    x = Activation(act)(x)\n",
        "    if dp>0: x = Dropout(dp)(x)\n",
        "    x = Conv2D(filters, k, padding='same')(x)\n",
        "    if bn: x = BatchNormalization()(x)\n",
        "    x = Activation(act)(x)\n",
        "    return x\n",
        "\n",
        "def up_block(x, skip, filters):\n",
        "    x = UpSampling2D((2,2))(x)\n",
        "    x = Concatenate()([x, skip])\n",
        "    x = conv_block(x, filters)\n",
        "    return x\n",
        "\n",
        "def build_unet_resnet50(input_shape=(128,128,3), freeze=True):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    # ResNet50 backbone\n",
        "    backbone = ResNet50(include_top=False, weights='imagenet', input_tensor=inputs)\n",
        "    # Feature maps for skips\n",
        "    skips = {\n",
        "        \"c1\": backbone.get_layer(\"conv1_relu\").output,          # 64, /2\n",
        "        \"c2\": backbone.get_layer(\"conv2_block3_out\").output,    # 256, /4\n",
        "        \"c3\": backbone.get_layer(\"conv3_block4_out\").output,    # 512, /8\n",
        "        \"c4\": backbone.get_layer(\"conv4_block6_out\").output,    # 1024, /16\n",
        "    }\n",
        "    x = backbone.get_layer(\"conv5_block3_out\").output           # 2048, /32\n",
        "    # Decoder\n",
        "    x = up_block(x, skips[\"c4\"], 512)\n",
        "    x = up_block(x, skips[\"c3\"], 256)\n",
        "    x = up_block(x, skips[\"c2\"], 128)\n",
        "    x = up_block(x, skips[\"c1\"], 64)\n",
        "    x = UpSampling2D((2,2))(x)  # back to /1\n",
        "    outputs = Conv2D(1, 1, activation=\"sigmoid\")(x)\n",
        "    model = Model(inputs, outputs, name=\"UNet_ResNet50\")\n",
        "    if freeze:\n",
        "        for l in backbone.layers:\n",
        "            l.trainable = False\n",
        "    return model\n",
        "\n",
        "def build_unet_vgg16(input_shape=(128,128,3), freeze=True):\n",
        "    inputs = Input(shape=input_shape)\n",
        "    backbone = VGG16(include_top=False, weights='imagenet', input_tensor=inputs)\n",
        "    # VGG blocks\n",
        "    b1 = backbone.get_layer(\"block1_conv2\").output   # /2, 64\n",
        "    b2 = backbone.get_layer(\"block2_conv2\").output   # /4, 128\n",
        "    b3 = backbone.get_layer(\"block3_conv3\").output   # /8, 256\n",
        "    b4 = backbone.get_layer(\"block4_conv3\").output   # /16, 512\n",
        "    b5 = backbone.get_layer(\"block5_conv3\").output   # /32, 512\n",
        "    # Decoder\n",
        "    x = up_block(b5, b4, 512)\n",
        "    x = up_block(x, b3, 256)\n",
        "    x = up_block(x, b2, 128)\n",
        "    x = up_block(x, b1, 64)\n",
        "    x = UpSampling2D((2,2))(x)  # back to /1 from /2\n",
        "    outputs = Conv2D(1, 1, activation=\"sigmoid\")(x)\n",
        "    model = Model(inputs, outputs, name=\"UNet_VGG16\")\n",
        "    if freeze:\n",
        "        for l in backbone.layers:\n",
        "            l.trainable = False\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "40c35739",
      "metadata": {
        "id": "40c35739"
      },
      "source": [
        "\n",
        "## Training helpers\n",
        "We compile with **Adam**, `bce_dice_loss`, and track **Dice** & **IoU**.  \n",
        "Two runs can be performed back-to-back: ResNet50-encoder and VGG16-encoder.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06f97126",
      "metadata": {
        "id": "06f97126"
      },
      "outputs": [],
      "source": [
        "def compile_model(m, lr=1e-3):\n",
        "    m.compile(optimizer=Adam(lr),\n",
        "              loss=bce_dice_loss,\n",
        "              metrics=[dice_coef, iou_coef])\n",
        "    return m\n",
        "\n",
        "def train_model(model, X_tr, Y_tr, X_va, Y_va, tag, epochs=EPOCHS):\n",
        "    ckpt_path = f\"/mnt/data/tgs_{tag}_best.h5\"\n",
        "    callbacks = [\n",
        "        ModelCheckpoint(ckpt_path, monitor=\"val_dice_coef\", mode=\"max\",\n",
        "                        save_best_only=True, save_weights_only=True, verbose=1),\n",
        "        ReduceLROnPlateau(monitor=\"val_dice_coef\", factor=0.5, patience=3,\n",
        "                          mode=\"max\", verbose=1, min_lr=1e-6),\n",
        "        EarlyStopping(monitor=\"val_dice_coef\", patience=6, mode=\"max\",\n",
        "                      restore_best_weights=True, verbose=1),\n",
        "        CSVLogger(f\"/mnt/data/tgs_{tag}_log.csv\", append=False)\n",
        "    ]\n",
        "    hist = model.fit(X_tr, Y_tr, validation_data=(X_va, Y_va),\n",
        "                     epochs=epochs, batch_size=BATCH_SIZE, callbacks=callbacks, verbose=1)\n",
        "    # Load best\n",
        "    if os.path.exists(ckpt_path):\n",
        "        model.load_weights(ckpt_path)\n",
        "    val_metrics = model.evaluate(X_va, Y_va, verbose=0)\n",
        "    print(f\"[{tag}] Val metrics: \" + \", \".join(f\"{n}={v:.4f}\" for n,v in zip(model.metrics_names, val_metrics)))\n",
        "    return model, hist"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7c6e1901",
      "metadata": {
        "id": "7c6e1901"
      },
      "source": [
        "\n",
        "## Run: ResNet50 encoder\n",
        "Freeze backbone for stability, then you can unfreeze and fine-tune for a few epochs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2701142b",
      "metadata": {
        "id": "2701142b"
      },
      "outputs": [],
      "source": [
        "resnet_model = compile_model(build_unet_resnet50((IMG_SIZE,IMG_SIZE,3), freeze=FREEZE_ENCODER), lr=1e-3)\n",
        "resnet_model, resnet_hist = train_model(resnet_model, X_tr, Y_tr, X_va, Y_va, tag=\"resnet50\", epochs=EPOCHS)\n",
        "\n",
        "# Optional fine-tuning (unfreeze):\n",
        "for l in resnet_model.layers:\n",
        "    l.trainable = True\n",
        "resnet_model = compile_model(resnet_model, lr=1e-4)\n",
        "resnet_model, resnet_hist2 = train_model(resnet_model, X_tr, Y_tr, X_va, Y_va, tag=\"resnet50_ft\", epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e51b30ea",
      "metadata": {
        "id": "e51b30ea"
      },
      "source": [
        "\n",
        "## Run: VGG16 encoder\n",
        "Same procedure for VGG16.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c2bacaa1",
      "metadata": {
        "id": "c2bacaa1"
      },
      "outputs": [],
      "source": [
        "vgg_model = compile_model(build_unet_vgg16((IMG_SIZE,IMG_SIZE,3), freeze=FREEZE_ENCODER), lr=1e-3)\n",
        "vgg_model, vgg_hist = train_model(vgg_model, X_tr, Y_tr, X_va, Y_va, tag=\"vgg16\", epochs=EPOCHS)\n",
        "\n",
        "# Optional fine-tuning\n",
        "for l in vgg_model.layers:\n",
        "    l.trainable = True\n",
        "vgg_model = compile_model(vgg_model, lr=1e-4)\n",
        "vgg_model, vgg_hist2 = train_model(vgg_model, X_tr, Y_tr, X_va, Y_va, tag=\"vgg16_ft\", epochs=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e86131e6",
      "metadata": {
        "id": "e86131e6"
      },
      "source": [
        "\n",
        "## Learning curves\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "90648a9c",
      "metadata": {
        "id": "90648a9c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def plot_history(hist, label):\n",
        "    h = hist.history\n",
        "    plt.figure(figsize=(12,4))\n",
        "    plt.subplot(1,2,1)\n",
        "    plt.plot(h['loss'], label='train')\n",
        "    plt.plot(h['val_loss'], label='val')\n",
        "    plt.title(f'Loss — {label}')\n",
        "    plt.legend()\n",
        "    plt.subplot(1,2,2)\n",
        "    key = 'dice_coef' if 'dice_coef' in h else list(h.keys())[1]\n",
        "    plt.plot(h[key], label='train')\n",
        "    plt.plot(h['val_'+key], label='val')\n",
        "    plt.title(f'Dice — {label}')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "plot_history(resnet_hist, \"ResNet50\")\n",
        "plot_history(vgg_hist, \"VGG16\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4625b006",
      "metadata": {
        "id": "4625b006"
      },
      "source": [
        "\n",
        "## Qualitative results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5207319a",
      "metadata": {
        "id": "5207319a"
      },
      "outputs": [],
      "source": [
        "def visualize_preds(model, X, Y, n=6):\n",
        "    idx = np.random.choice(len(X), n, replace=False)\n",
        "    preds = model.predict(X[idx], batch_size=n)\n",
        "    plt.figure(figsize=(12, 2*n))\n",
        "    for i, k in enumerate(idx):\n",
        "        plt.subplot(n,3,3*i+1); plt.imshow(X[k].squeeze(), cmap='gray'); plt.title(\"Image\"); plt.axis('off')\n",
        "        plt.subplot(n,3,3*i+2); plt.imshow(Y[k].squeeze(), cmap='gray'); plt.title(\"Mask\"); plt.axis('off')\n",
        "        plt.subplot(n,3,3*i+3); plt.imshow((preds[i].squeeze()>0.5).astype(np.float32), cmap='gray'); plt.title(\"Pred\"); plt.axis('off')\n",
        "    plt.tight_layout(); plt.show()\n",
        "\n",
        "print(\"ResNet50 samples:\"); visualize_preds(resnet_model, X_va, Y_va, n=4)\n",
        "print(\"VGG16 samples:\"); visualize_preds(vgg_model, X_va, Y_va, n=4)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
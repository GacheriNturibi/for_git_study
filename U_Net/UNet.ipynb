{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "33e130f5",
      "metadata": {
        "id": "33e130f5"
      },
      "source": [
        "\n",
        "# Image Segmentation with U‑Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4a96101e",
      "metadata": {
        "id": "4a96101e"
      },
      "outputs": [],
      "source": [
        "# Environment & GPU check\n",
        "import os, sys, math, glob, json, shutil, zipfile, random\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reproducibility\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    print(\"TensorFlow:\", tf.__version__)\n",
        "    gpus = getattr(tf.config, \"list_physical_devices\", lambda *_: [])(\"GPU\")\n",
        "    print(\"GPUs:\", gpus)\n",
        "except Exception as e:\n",
        "    print(\"TensorFlow not found (you can install TF 2.x).\", e)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cd90a98a",
      "metadata": {
        "id": "cd90a98a"
      },
      "source": [
        "\n",
        "## 1) Dataset setup (TGS Salt)\n",
        "\n",
        "You have two options:\n",
        "\n",
        "**A. Kaggle API** (recommended)\n",
        "1. Upload your `kaggle.json` (API token) to this runtime, or place it under `~/.kaggle/kaggle.json`.\n",
        "2. Run the cell below to download and unzip the competition data.\n",
        "\n",
        "**B. Local/Pre‑downloaded**\n",
        "- If you already have the dataset, set `DATA_DIR` below to the root containing `train/` and `test/` folders\n",
        "  with `images/` and `masks/` inside `train/` (typical layout).\n",
        "\n",
        "The expected structure after unzip (typical community mirrors):  \n",
        "```\n",
        "data/\n",
        "  train/\n",
        "    images/  (101x101 PNGs)\n",
        "    masks/   (101x101 PNGs)\n",
        "  test/\n",
        "    images/\n",
        "  depths.csv         (optional metadata)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b11eb353",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "b11eb353",
        "outputId": "01984575-216b-4304-cae6-25571c845850"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "'str' object has no attribute 'cwd'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1978566357.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Choose where to place data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mPath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"content/sample_data\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mBASE\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m\"data_tgs\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mBASE\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmkdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexist_ok\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'cwd'"
          ]
        }
      ],
      "source": [
        "# Choose where to place data\n",
        "Path = \"content/sample_data\"\n",
        "BASE = Path.cwd() / \"data_tgs\"\n",
        "BASE.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "USE_KAGGLE = False  # flip to True to use Kaggle API in this notebook\n",
        "\n",
        "if USE_KAGGLE:\n",
        "    # --- Kaggle download (requires kaggle.json) ---\n",
        "    # In Colab: from google.colab import files; files.upload()  # upload kaggle.json first\n",
        "    kaggle_dir = Path.home() / \".kaggle\"\n",
        "    kaggle_dir.mkdir(exist_ok=True)\n",
        "    if Path(\"kaggle.json\").exists():\n",
        "        shutil.move(\"kaggle.json\", kaggle_dir / \"kaggle.json\")\n",
        "        os.chmod(kaggle_dir / \"kaggle.json\", 0o600)\n",
        "    # Install kaggle CLI if needed\n",
        "    try:\n",
        "        import kaggle  # noqa: F401\n",
        "    except:\n",
        "        !pip -q install kaggle\n",
        "    # This competition is archived; mirrors exist.\n",
        "    # If the official download is unavailable, place your zips under BASE and skip this.\n",
        "    print(\"Attempting kaggle download (may require acceptance):\")\n",
        "    !kaggle competitions download -c tgs-salt-identification-challenge -p \"{BASE}\"\n",
        "    # Unzip files we care about (some mirrors name files differently)\n",
        "    for z in BASE.glob(\"*.zip\"):\n",
        "        with zipfile.ZipFile(z, \"r\") as f:\n",
        "            f.extractall(BASE)\n",
        "else:\n",
        "    print(\"Set USE_KAGGLE=True to download via Kaggle API, or copy your dataset under:\", BASE)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d7bd35b5",
      "metadata": {
        "id": "d7bd35b5"
      },
      "source": [
        "\n",
        "## 2) Load, preprocess, and visualize\n",
        "\n",
        "- The original images are **101×101** grayscale.  \n",
        "- We will **pad to 128×128** for convenience (power‑of‑two makes UNet easier).  \n",
        "- Scale pixel values to `[0,1]`.  \n",
        "- Split into **train/validation**.  \n",
        "- Provide both a **tf.data** pipeline and a simple **NumPy** loader to keep it flexible.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "88e1d004",
      "metadata": {
        "id": "88e1d004"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "\n",
        "def load_pairs(root):\n",
        "    \"\"\"Return lists of (image_path, mask_path).\"\"\"\n",
        "    root = Path(root)\n",
        "    img_dir = root / \"train\" / \"images\"\n",
        "    msk_dir = root / \"train\" / \"masks\"\n",
        "    if not img_dir.exists() or not msk_dir.exists():\n",
        "        raise FileNotFoundError(f\"Expected {img_dir} and {msk_dir}\")\n",
        "    img_paths = sorted(img_dir.glob(\"*.png\"))\n",
        "    pairs = []\n",
        "    for p in img_paths:\n",
        "        m = msk_dir / p.name\n",
        "        if m.exists():\n",
        "            pairs.append((p, m))\n",
        "    return pairs\n",
        "\n",
        "def pad_to_square(img, size=128):\n",
        "    \"\"\"Pad a 2D array (H,W) with zeros to (size,size) centered.\"\"\"\n",
        "    h, w = img.shape\n",
        "    out = np.zeros((size, size), dtype=img.dtype)\n",
        "    y0 = (size - h)//2\n",
        "    x0 = (size - w)//2\n",
        "    out[y0:y0+h, x0:x0+w] = img\n",
        "    return out\n",
        "\n",
        "def load_arrays(pairs, size=128):\n",
        "    X, Y = [], []\n",
        "    for ip, mp in pairs:\n",
        "        img = np.array(Image.open(ip))          # shape (101,101)\n",
        "        msk = np.array(Image.open(mp))          # shape (101,101)\n",
        "        img = pad_to_square(img, size)\n",
        "        msk = pad_to_square(msk, size)\n",
        "        X.append(img[None, ...])    # add channel dim -> (1,H,W)\n",
        "        Y.append((msk>0).astype(np.float32)[None, ...])\n",
        "    X = np.stack(X, axis=0).astype(np.float32) / 255.0  # (N,1,H,W)\n",
        "    Y = np.stack(Y, axis=0).astype(np.float32)          # (N,1,H,W)\n",
        "    return X, Y\n",
        "\n",
        "DATA_DIR = BASE   # set to your data root if different\n",
        "pairs = []\n",
        "try:\n",
        "    pairs = load_pairs(DATA_DIR)\n",
        "    print(\"Found pairs:\", len(pairs))\n",
        "except Exception as e:\n",
        "    print(\"Data not found yet:\", e)\n",
        "\n",
        "# quick peek\n",
        "if pairs:\n",
        "    Xnp, Ynp = load_arrays(pairs[:8], size=128)\n",
        "    print(\"Batch shapes:\", Xnp.shape, Ynp.shape)\n",
        "    # visualize a few\n",
        "    fig, axes = plt.subplots(2, 4, figsize=(10,5))\n",
        "    for i, ax in enumerate(axes.ravel()):\n",
        "        ax.imshow(Xnp[i,0])\n",
        "        ax.set_title(f\"mask sum={int(Ynp[i,0].sum())}\")\n",
        "        ax.axis(\"off\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e541639f",
      "metadata": {
        "id": "e541639f"
      },
      "outputs": [],
      "source": [
        "# Split\n",
        "def train_val_split(pairs, val_ratio=0.2, seed=42):\n",
        "    r = random.Random(seed)\n",
        "    pairs = pairs.copy()\n",
        "    r.shuffle(pairs)\n",
        "    n = len(pairs)\n",
        "    nv = int(n*val_ratio)\n",
        "    return pairs[nv:], pairs[:nv]\n",
        "\n",
        "train_pairs, val_pairs = train_val_split(pairs, 0.2, 42) if pairs else ([], [])\n",
        "print(\"Train/Val sizes:\", len(train_pairs), len(val_pairs))\n",
        "\n",
        "# tf.data helpers (optional; works when TF is available)\n",
        "def make_tf_dataset(pairs, size=128, batch=16, shuffle=True):\n",
        "    import tensorflow as tf\n",
        "    ipaths = [str(p[0]) for p in pairs]\n",
        "    mpaths = [str(p[1]) for p in pairs]\n",
        "    ds = tf.data.Dataset.from_tensor_slices((ipaths, mpaths))\n",
        "    if shuffle:\n",
        "        ds = ds.shuffle(len(ipaths), seed=42, reshuffle_each_iteration=True)\n",
        "    def _load(ip, mp):\n",
        "        img = tf.io.read_file(ip)\n",
        "        img = tf.io.decode_png(img, channels=1)\n",
        "        img = tf.image.convert_image_dtype(img, tf.float32)  # [0,1]\n",
        "        img = tf.squeeze(img, axis=-1)                       # (H,W)\n",
        "        msk = tf.io.read_file(mp)\n",
        "        msk = tf.io.decode_png(msk, channels=1)\n",
        "        msk = tf.cast(msk>0, tf.float32)\n",
        "        msk = tf.squeeze(msk, axis=-1)\n",
        "        img = tf.numpy_function(lambda a: pad_to_square(a, size), [img], tf.float32)\n",
        "        msk = tf.numpy_function(lambda a: pad_to_square(a, size), [msk], tf.float32)\n",
        "        img = tf.reshape(img, [size, size])\n",
        "        msk = tf.reshape(msk, [size, size])\n",
        "        img = tf.expand_dims(img, -1)  # (H,W,1) for tf.keras\n",
        "        msk = tf.expand_dims(msk, -1)\n",
        "        return img, msk\n",
        "    ds = ds.map(_load, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    ds = ds.batch(batch).prefetch(tf.data.AUTOTUNE)\n",
        "    return ds\n",
        "\n",
        "tf_train = make_tf_dataset(train_pairs, size=128, batch=16) if train_pairs else None\n",
        "tf_val   = make_tf_dataset(val_pairs,   size=128, batch=16, shuffle=False) if val_pairs else None"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "55edf0b5",
      "metadata": {
        "id": "55edf0b5"
      },
      "source": [
        "\n",
        "## 3) Loss & metrics\n",
        "\n",
        "We use **binary cross‑entropy** and add **Dice** and **IoU** as monitoring metrics.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91a8de38",
      "metadata": {
        "id": "91a8de38"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def dice_coef(y_true, y_pred, smooth=1e-6):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    inter  = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
        "    denom  = tf.reduce_sum(y_true + y_pred, axis=[1,2,3])\n",
        "    dice   = (2.0*inter + smooth) / (denom + smooth)\n",
        "    return tf.reduce_mean(dice)\n",
        "\n",
        "def iou_coef(y_true, y_pred, smooth=1e-6):\n",
        "    y_true = tf.cast(y_true, tf.float32)\n",
        "    y_pred = tf.cast(y_pred, tf.float32)\n",
        "    inter  = tf.reduce_sum(y_true * y_pred, axis=[1,2,3])\n",
        "    union  = tf.reduce_sum(y_true + y_pred - y_true*y_pred, axis=[1,2,3])\n",
        "    iou    = (inter + smooth) / (union + smooth)\n",
        "    return tf.reduce_mean(iou)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "74d57aed",
      "metadata": {
        "id": "74d57aed"
      },
      "source": [
        "\n",
        "## 4) Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "86250375",
      "metadata": {
        "id": "86250375"
      },
      "outputs": [],
      "source": [
        "USE_ZHIXUHAO = True  # set False to force local model\n",
        "\n",
        "def get_unet(input_shape=(128,128,1)):\n",
        "    \"\"\"Local compact U‑Net in case the public repo isn't available.\"\"\"\n",
        "    from tensorflow.keras import layers, models\n",
        "    inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "    def conv_block(x, f):\n",
        "        x = layers.Conv2D(f, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "        x = layers.Conv2D(f, 3, padding=\"same\", activation=\"relu\")(x)\n",
        "        return x\n",
        "\n",
        "    c1 = conv_block(inputs, 32); p1 = layers.MaxPooling2D(2)(c1)\n",
        "    c2 = conv_block(p1,     64); p2 = layers.MaxPooling2D(2)(c2)\n",
        "    c3 = conv_block(p2,    128); p3 = layers.MaxPooling2D(2)(c3)\n",
        "    c4 = conv_block(p3,    256); p4 = layers.MaxPooling2D(2)(c4)\n",
        "\n",
        "    bn = conv_block(p4, 512)\n",
        "\n",
        "    u4 = layers.UpSampling2D()(bn); u4 = layers.Concatenate()([u4, c4]); c5 = conv_block(u4, 256)\n",
        "    u3 = layers.UpSampling2D()(c5); u3 = layers.Concatenate()([u3, c3]); c6 = conv_block(u3, 128)\n",
        "    u2 = layers.UpSampling2D()(c6); u2 = layers.Concatenate()([u2, c2]); c7 = conv_block(u2, 64)\n",
        "    u1 = layers.UpSampling2D()(c7); u1 = layers.Concatenate()([u1, c1]); c8 = conv_block(u1, 32)\n",
        "\n",
        "    outputs = layers.Conv2D(1, 1, activation=\"sigmoid\")(c8)\n",
        "    return models.Model(inputs, outputs, name=\"UNet_local\")\n",
        "\n",
        "model = None\n",
        "if USE_ZHIXUHAO:\n",
        "    try:\n",
        "        # Try to clone/import the repo\n",
        "        import importlib.util, sys, subprocess, types\n",
        "        if not Path(\"unet_repo\").exists():\n",
        "            !git clone --depth 1 https://github.com/zhixuhao/unet.git unet_repo\n",
        "        sys.path.insert(0, str(Path(\"unet_repo\")))\n",
        "        from model import unet\n",
        "        model = unet(input_size=(128,128,1))\n",
        "        print(\"Using zhixuhao/unet model\")\n",
        "    except Exception as e:\n",
        "        print(\"Falling back to local U-Net:\", e)\n",
        "        model = get_unet()\n",
        "else:\n",
        "    model = get_unet()\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b4ea5b1c",
      "metadata": {
        "id": "b4ea5b1c"
      },
      "source": [
        "\n",
        "## 5) Train\n",
        "\n",
        "We compile with `binary_crossentropy` and monitor Dice/IoU.  \n",
        "Early stopping and model checkpointing help prevent overfitting.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e60d31cf",
      "metadata": {
        "id": "e60d31cf"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "model.compile(optimizer=Adam(1e-3), loss=\"binary_crossentropy\",\n",
        "              metrics=[\"accuracy\", dice_coef, iou_coef])\n",
        "\n",
        "ckpt_path = \"unet_tgs_best.h5\"\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor=\"val_iou_coef\", patience=10, mode=\"max\", restore_best_weights=True),\n",
        "    ModelCheckpoint(ckpt_path, monitor=\"val_iou_coef\", mode=\"max\", save_best_only=True, verbose=1),\n",
        "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=5, verbose=1)\n",
        "]\n",
        "\n",
        "EPOCHS = 40\n",
        "if train_pairs:\n",
        "    history = model.fit(tf_train,\n",
        "                        validation_data=tf_val,\n",
        "                        epochs=EPOCHS,\n",
        "                        callbacks=callbacks)\n",
        "else:\n",
        "    print(\"No data found yet. Once data is available, re-run this cell to train.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7f34b74",
      "metadata": {
        "id": "a7f34b74"
      },
      "source": [
        "\n",
        "## 6) Learning curves\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7ca036e",
      "metadata": {
        "id": "e7ca036e"
      },
      "outputs": [],
      "source": [
        "if 'history' in locals():\n",
        "    h = history.history\n",
        "    fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
        "    ax[0].plot(h[\"loss\"]); ax[0].plot(h.get(\"val_loss\", [])); ax[0].set_title(\"Loss\"); ax[0].set_xlabel(\"epoch\")\n",
        "    ax[1].plot(h.get(\"iou_coef\", [])); ax[1].plot(h.get(\"val_iou_coef\", [])); ax[1].set_title(\"IoU\"); ax[1].set_xlabel(\"epoch\")\n",
        "    ax[0].legend([\"train\",\"val\"]); ax[1].legend([\"train\",\"val\"])\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Train first to see curves.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d2cfa0f6",
      "metadata": {
        "id": "d2cfa0f6"
      },
      "source": [
        "\n",
        "## 7) Inference & qualitative results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a4230295",
      "metadata": {
        "id": "a4230295"
      },
      "outputs": [],
      "source": [
        "def predict_and_plot(n=6, th=0.5):\n",
        "    if not val_pairs:\n",
        "        print(\"No validation data to show.\")\n",
        "        return\n",
        "    samp = random.sample(val_pairs, min(n, len(val_pairs)))\n",
        "    Xb, Yb = load_arrays(samp, size=128)\n",
        "    preds = model.predict(np.transpose(Xb, (0,2,3,1)))  # (N,128,128,1)\n",
        "    preds = preds[...,0]\n",
        "    fig, axes = plt.subplots(3, len(samp), figsize=(3*len(samp), 8))\n",
        "    for i,(ip,mp) in enumerate(samp):\n",
        "        axes[0,i].imshow(Xb[i,0]); axes[0,i].set_title(Path(ip).name); axes[0,i].axis(\"off\")\n",
        "        axes[1,i].imshow(Yb[i,0]); axes[1,i].set_title(\"GT mask\"); axes[1,i].axis(\"off\")\n",
        "        axes[2,i].imshow((preds[i]>th).astype(np.float32)); axes[2,i].set_title(\"Pred>th\"); axes[2,i].axis(\"off\")\n",
        "    plt.show()\n",
        "\n",
        "# Run if trained\n",
        "if pairs:\n",
        "    try:\n",
        "        predict_and_plot(6, th=0.5)\n",
        "    except Exception as e:\n",
        "        print(\"Run training first. Error:\", e)\n",
        "else:\n",
        "    print(\"Add data first to demo predictions.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "559ccf6d",
      "metadata": {
        "id": "559ccf6d"
      },
      "source": [
        "## Appendix - Utilities\n",
        "\n",
        "- Lightweight output‑size helper for conv/pool strides (handy when changing input sizes)\n",
        "- Simple RLE encoder/decoder stubs if you want to submit to Kaggle (optional; fill as needed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64572775",
      "metadata": {
        "id": "64572775"
      },
      "outputs": [],
      "source": [
        "def conv2d_out(H, W, kH=3, kW=3, stride=1, pad=0):\n",
        "    Hout = (H + 2*pad - kH)//stride + 1\n",
        "    Wout = (W + 2*pad - kW)//stride + 1\n",
        "    return Hout, Wout\n",
        "\n",
        "print(\"Example conv2d_out(128,128, k=3, s=1, p=0) ->\", conv2d_out(128,128))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "accelerator": "TPU",
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}